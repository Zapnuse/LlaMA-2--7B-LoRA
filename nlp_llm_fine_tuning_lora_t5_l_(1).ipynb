{
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30636,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 37245.812384,
      "end_time": "2024-01-19T23:50:36.51461",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-19T13:29:50.702226",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e5fcfd23fb44aa9a5e64e9aa0aa01c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5067c9ad62104c389c04a67fd0bacf48",
              "IPY_MODEL_e14c53ea06e24a1db4d3ac1378f13ec9",
              "IPY_MODEL_fac13b79a30141afae7b77090347cb62"
            ],
            "layout": "IPY_MODEL_f994ed4d20ed41a68c347d7b2bae8d85"
          }
        },
        "5067c9ad62104c389c04a67fd0bacf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79f5c166a014048998dd2a2b8148558",
            "placeholder": "​",
            "style": "IPY_MODEL_c87738656c1940699da500d6c667a79d",
            "value": "Downloading builder script: 100%"
          }
        },
        "e14c53ea06e24a1db4d3ac1378f13ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d40e4eccd54621925838bd1d734eb5",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbec0507205c483681568ce064d035e4",
            "value": 6270
          }
        },
        "fac13b79a30141afae7b77090347cb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8f79bfbceb46af863f132de18f9d00",
            "placeholder": "​",
            "style": "IPY_MODEL_0d7e1336649a42aaa378d1b032ab1864",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 198kB/s]"
          }
        },
        "f994ed4d20ed41a68c347d7b2bae8d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79f5c166a014048998dd2a2b8148558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87738656c1940699da500d6c667a79d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d40e4eccd54621925838bd1d734eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbec0507205c483681568ce064d035e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f8f79bfbceb46af863f132de18f9d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7e1336649a42aaa378d1b032ab1864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb2b69ad55db4e39ba1469a8f5ffffc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d569eee6a06f462e8d68ec163e955140",
              "IPY_MODEL_a3b99937baf042ec9398f59b5c295a2e",
              "IPY_MODEL_6e4cf55605d64c1f8ddaf84226f3ce0c"
            ],
            "layout": "IPY_MODEL_83222dc452f94d53a9d2e8491044d8ab"
          }
        },
        "d569eee6a06f462e8d68ec163e955140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d481d3a098ac49b5bdc29729d9a2893c",
            "placeholder": "​",
            "style": "IPY_MODEL_9916108906df4e219b5a18147bb80d35",
            "value": "Downloading data: 100%"
          }
        },
        "a3b99937baf042ec9398f59b5c295a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a306d92b73d44229739cc91cc31604e",
            "max": 39283467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_742b46c4f34644f9bdf4ed0d868ff1f0",
            "value": 39283467
          }
        },
        "6e4cf55605d64c1f8ddaf84226f3ce0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbe782d605c4bd5abe91949b39e354a",
            "placeholder": "​",
            "style": "IPY_MODEL_16bb356e37184052bbfd883dcf46bb1d",
            "value": " 39.3M/39.3M [00:00&lt;00:00, 47.8MB/s]"
          }
        },
        "83222dc452f94d53a9d2e8491044d8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d481d3a098ac49b5bdc29729d9a2893c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9916108906df4e219b5a18147bb80d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a306d92b73d44229739cc91cc31604e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742b46c4f34644f9bdf4ed0d868ff1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bbe782d605c4bd5abe91949b39e354a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16bb356e37184052bbfd883dcf46bb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bff284fb3dc4f4c869e2b6474b09aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27f616fa2fb046e4942d3fd2346ad4ee",
              "IPY_MODEL_f620a98fecc74cd187265a9b49569c92",
              "IPY_MODEL_bc1c185f0a074bc7a1ca1bd9f7c1601b"
            ],
            "layout": "IPY_MODEL_15933885883140cdbb3029db302fbe45"
          }
        },
        "27f616fa2fb046e4942d3fd2346ad4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ed372f1c6b4ed4a86b950bd78fc5e3",
            "placeholder": "​",
            "style": "IPY_MODEL_072671e7fa9a49adafa8a454ee57c7ce",
            "value": "Generating train split: 100%"
          }
        },
        "f620a98fecc74cd187265a9b49569c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e7bba8af26463986c731d2db65e75f",
            "max": 24322,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f73da608d70648968b602b9d2cb71991",
            "value": 24322
          }
        },
        "bc1c185f0a074bc7a1ca1bd9f7c1601b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4f875e7902641bda9f5ab0566ef4d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_18e3929fffbc48c892b6828245b3f8b8",
            "value": " 24322/24322 [00:00&lt;00:00, 47188.96 examples/s]"
          }
        },
        "15933885883140cdbb3029db302fbe45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ed372f1c6b4ed4a86b950bd78fc5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072671e7fa9a49adafa8a454ee57c7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04e7bba8af26463986c731d2db65e75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f73da608d70648968b602b9d2cb71991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4f875e7902641bda9f5ab0566ef4d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e3929fffbc48c892b6828245b3f8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab64792e47a48f8accf715e27aa0476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8aeb664adfb3488d81b09c97781e61c7",
              "IPY_MODEL_18b16056803c48d99c13a1919a4077e3",
              "IPY_MODEL_c1f9f69a22544e73b945064c694f5fc2"
            ],
            "layout": "IPY_MODEL_85f89c9515e44c8480e70e68b3f3ec72"
          }
        },
        "8aeb664adfb3488d81b09c97781e61c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c86ef1fdb1a49b3b8671de1b2a97820",
            "placeholder": "​",
            "style": "IPY_MODEL_9432acf5ca564c98972d26ce196b8ce3",
            "value": "Downloading readme: 100%"
          }
        },
        "18b16056803c48d99c13a1919a4077e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78de475054244fec900aa07981540c77",
            "max": 404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5303b9f5c68649a294a7d67038a4285a",
            "value": 404
          }
        },
        "c1f9f69a22544e73b945064c694f5fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71280fc671cf42e8a687806bb9b9252a",
            "placeholder": "​",
            "style": "IPY_MODEL_61e0935a08454625afac1dbad89dd561",
            "value": " 404/404 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "85f89c9515e44c8480e70e68b3f3ec72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c86ef1fdb1a49b3b8671de1b2a97820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9432acf5ca564c98972d26ce196b8ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78de475054244fec900aa07981540c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5303b9f5c68649a294a7d67038a4285a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71280fc671cf42e8a687806bb9b9252a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e0935a08454625afac1dbad89dd561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc703dcc0ff4927b33114d1c5230a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c15b2134567472783d07f2e7c675856",
              "IPY_MODEL_b38cc735b96149d7874cfce1c6397a00",
              "IPY_MODEL_ab13006a2f7d4a10a6c43d6a4aa9a3ff"
            ],
            "layout": "IPY_MODEL_8f9b9d335a154cd2a23db931f19f2cd8"
          }
        },
        "5c15b2134567472783d07f2e7c675856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea025339aed4a5e8b4b4ebc94accc28",
            "placeholder": "​",
            "style": "IPY_MODEL_ee2f50f2d9814d579a7164cef39ca223",
            "value": "Downloading data: 100%"
          }
        },
        "b38cc735b96149d7874cfce1c6397a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3327140dc6d9489fb5b3f2f2c74e71cd",
            "max": 421971,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0acadc1d67f4456a631e9df98d1789a",
            "value": 421971
          }
        },
        "ab13006a2f7d4a10a6c43d6a4aa9a3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3339fac297f74999b6e9239fbb19b020",
            "placeholder": "​",
            "style": "IPY_MODEL_f14c31f8a28d4ccebeba8ba13ca44940",
            "value": " 422k/422k [00:00&lt;00:00, 5.90MB/s]"
          }
        },
        "8f9b9d335a154cd2a23db931f19f2cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea025339aed4a5e8b4b4ebc94accc28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2f50f2d9814d579a7164cef39ca223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3327140dc6d9489fb5b3f2f2c74e71cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0acadc1d67f4456a631e9df98d1789a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3339fac297f74999b6e9239fbb19b020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14c31f8a28d4ccebeba8ba13ca44940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b13b71b3c5e04692a7fb7be72132861f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7276cd7f393f4e5691c5c6aadb670712",
              "IPY_MODEL_004f2949be1d4a3685d9f649e7197bec",
              "IPY_MODEL_858f14d5abb74d079a2e13cf9e25e250"
            ],
            "layout": "IPY_MODEL_c6b896c7670145919c4d3ee889cc7f68"
          }
        },
        "7276cd7f393f4e5691c5c6aadb670712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb386a0842c74dadbb6298eaabcbb888",
            "placeholder": "​",
            "style": "IPY_MODEL_e9017325da6d4fde8610671abc4e0163",
            "value": "Generating train split: 100%"
          }
        },
        "004f2949be1d4a3685d9f649e7197bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5e2ad69ee642729da3bb9051a22c79",
            "max": 360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b45647be4e84f62b7306d7303e1fc12",
            "value": 360
          }
        },
        "858f14d5abb74d079a2e13cf9e25e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93e86a68ee944cea19be9093db0cb89",
            "placeholder": "​",
            "style": "IPY_MODEL_b6d8080cc1684fd68c9e75d135469cd8",
            "value": " 360/360 [00:00&lt;00:00, 3403.24 examples/s]"
          }
        },
        "c6b896c7670145919c4d3ee889cc7f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb386a0842c74dadbb6298eaabcbb888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9017325da6d4fde8610671abc4e0163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5e2ad69ee642729da3bb9051a22c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b45647be4e84f62b7306d7303e1fc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c93e86a68ee944cea19be9093db0cb89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d8080cc1684fd68c9e75d135469cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "<a href=\"https://www.kaggle.com/code/yannicksteph/nlp-llm-fine-tuning-qa-lora-t5?scriptVersionId=159753452\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
      ],
      "metadata": {
        "id": "_OH9A6BDMZP9"
      },
      "cell_type": "markdown",
      "id": "_OH9A6BDMZP9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# | NLP | LLM | Fine-tuning | QA LoRA T5 |\n",
        "\n",
        "## Natural Language Processing (NLP) and Large Language Models (LLM) with Fine-Tuning LLM and make Question answering (QA) with LoRA and Flan-T5 Large\n",
        "\n",
        "![Learning](https://t3.ftcdn.net/jpg/06/14/01/52/360_F_614015247_EWZHvC6AAOsaIOepakhyJvMqUu5tpLfY.jpg)\n",
        "\n",
        "\n",
        "# <b>1 <span style='color:#78D118'>|</span> Overview</b>\n",
        "\n",
        "In this notebook we're going to Fine-Tuning LLM:\n",
        "\n",
        "<img src=\"https://github.com/YanSte/NLP-LLM-Fine-tuning-Trainer/blob/main/img_2.png?raw=true\" alt=\"Learning\" width=\"50%\">\n",
        "\n",
        "Many LLMs are general purpose models trained on a broad range of data and use cases. This enables them to perform well in a variety of applications, as shown in previous modules. It is not uncommon though to find situations where applying a general purpose model performs unacceptably for specific dataset or use case. This often does not mean that the general purpose model is unusable. Perhaps, with some new data and additional training the model could be improved, or fine-tuned, such that it produces acceptable results for the specific use case.\n",
        "\n",
        "<img src=\"https://github.com/YanSte/NLP-LLM-Fine-tuning-Trainer/blob/main/img_1.png?raw=true\" alt=\"Learning\" width=\"50%\">\n",
        "\n",
        "Fine-tuning uses a pre-trained model as a base and continues to train it with a new, task targeted dataset. Conceptually, fine-tuning leverages that which has already been learned by a model and aims to focus its learnings further for a specific task.\n",
        "\n",
        "It is important to recognize that fine-tuning is model training. The training process remains a resource intensive, and time consuming effort. Albeit fine-tuning training time is greatly shortened as a result of having started from a pre-trained model.\n",
        "\n",
        "<img src=\"https://github.com/YanSte/NLP-LLM-Fine-tuning-Trainer/blob/main/img_3.png?raw=true\" alt=\"Learning\" width=\"50%\">\n",
        "\n",
        "[Hugging Face Model](https://huggingface.co/YanSte/t5_large_fine_tuning_question_answering_hc3_chatgpt_prompts)\n",
        "\n",
        "### Overview definitions\n",
        "\n",
        "<br/>\n",
        "<details>\n",
        "  <summary style=\"list-style: none;\"><b>▶️ What is T5 Model?</b></summary>\n",
        "  <br/>\n",
        "  Multiple formats of FLAN-T5 models are available on Hugging Face, from small to extra-large models, and the bigger the model, the more parameters it has.\n",
        "\n",
        "  Below are the different model sizes available from the Hugging Face model card:\n",
        "  <br/>\n",
        "  <img src=\"https://images.datacamp.com/image/upload/v1699032555/image8_241fd08d9c.png\" alt=\"Learning\" width=\"50%\">\n",
        "\n",
        "  FLAN-T5 variants with their parameters and memory usage\n",
        "\n",
        "  Choosing the right model size\n",
        "  The choice of the right model size among the variants of FLAN-T5 highly depends on the following criteria:\n",
        "\n",
        "  - The specific requirements of the project\n",
        "  - The available computational resources\n",
        "  - The level of performance expected\n",
        "\n",
        "</details>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<details>\n",
        "  <summary style=\"list-style: none;\"><b>▶️ Fine-Tuning with LoRA?</b></summary>\n",
        "  <br/>\n",
        "  Fine-tuning, a crucial aspect of adapting pre-trained models to specific tasks, has witnessed a revolutionary approach known as Low Rank Adaptation (LoRA). Unlike conventional fine-tuning methods, LoRA strategically freezes pre-trained model weights and introduces trainable rank decomposition matrices into the Transformer architecture's layers. This innovative technique significantly reduces the number of trainable parameters, leading to expedited fine-tuning processes and mitigated overfitting.\n",
        "\n",
        "</details>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<details>\n",
        "  <summary style=\"list-style: none;\"><b>▶️ Text Generation vs Text2Text Generation?</b></summary>\n",
        "  <br/>\n",
        "\n",
        "  <b>Text Generation:</b>\n",
        "\n",
        "  Text Generation, also known as Causal Language Modeling, is the process of generating text that closely resembles human writing.\n",
        "\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*XDtcpv-m0SJRGSGB.png\" alt=\"Learning\" width=\"40%\">\n",
        "\n",
        "  It utilizes a Decoder-only architecture and operates in a left-to-right context. Text Generation is often employed for tasks such as sentence completion and generating the next lines of poetry when given a few lines as input. Examples of Text Generation models include the GPT family, BLOOM, and PaLM, which find applications in Chatbots, Text Completion, and content generation.\n",
        "\n",
        "  ```\n",
        "  from transformers import pipeline\n",
        "\n",
        "  task = \"text-generation\"\n",
        "  model_name = \"gpt2\"\n",
        "  max_output_length = 30\n",
        "  num_of_return_sequences = 2\n",
        "  input_text = \"Hello, \"\n",
        "\n",
        "  text_generator = pipeline(task, model=model_name)\n",
        "\n",
        "  text_generator(input_text, max_length=max_output_length, num_return_sequences=num_of_return_sequences)\n",
        "  ```\n",
        "    \n",
        "  <br/>\n",
        "\n",
        "  <b>Text2Text Generation:</b>\n",
        "\n",
        "  Text-to-Text Generation, also known as Sequence-to-Sequence Modeling, is the process of converting one piece of text into another.\n",
        "\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*7_yKVuJmhFxUAGPQ.png\" alt=\"Learning\" width=\"40%\">\n",
        "\n",
        "  Text-to-Text Generation involves transforming input text into a desired target text, making it a versatile approach. It is commonly used in tasks such as language translation, summarization, and question-answering.\n",
        "\n",
        "  Examples of Text-to-Text Generation models include Transformer-based architectures like T5 (Text-to-Text Transfer Transformer) and BART (Bart is not just another Reformatter).\n",
        "\n",
        "  ```\n",
        "  from transformers import pipeline\n",
        "\n",
        "  task = \"text2text-generation\"\n",
        "  model_name = \"t5-small\"\n",
        "  max_output_length = 50\n",
        "  num_of_return_sequences = 2\n",
        "  input_text = \"Translate the following English text to French: 'Hello, how are you?'\"\n",
        "\n",
        "  text_generator = pipeline(task, model=model_name)\n",
        "\n",
        "  text_generator(input_text, max_length=max_output_length, num_return_sequences=num_of_return_sequences)\n",
        "  ```\n",
        "    \n",
        "  <br/>\n",
        "    \n",
        "  In this example, we use the T5 model from Hugging Face to perform text-to-text generation. The input text is an English sentence that we want to translate into French. The model is capable of generating multiple possible translations.\n",
        "\n",
        "</details>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<details>\n",
        "  <summary style=\"list-style: none;\"><b>▶️ What is LoRA?</b></summary>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kzZ2_LZqBO9_hTi3.png\" alt=\"Learning\" width=\"30%\">\n",
        "\n",
        "  LoRA represents a paradigm shift in fine-tuning strategies, offering efficiency and effectiveness. By reducing the number of trainable parameters and GPU memory requirements, LoRA proves to be a powerful tool for tailoring pre-trained large models to specific tasks. This article explores how LoRA can be employed to create a personalized chatbot.\n",
        "\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJtZupeQVgp3s5HOBymcQw.png\" alt=\"Learning\" width=\"40%\">\n",
        "  <img src=\"https://github.com/YanSte/NLP-LLM-Fine-tuning-T5-Small-Reviews/blob/main/img_1.png?raw=true\" alt=\"Learning\" width=\"50%\">\n",
        "\n",
        "</details>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<details>\n",
        "  <summary style=\"list-style: none;\"><b>▶️ PeftModel vs get_peft_model?</b></summary>\n",
        "    \n",
        "  <br/>\n",
        "    \n",
        "  Note:\n",
        "  1. <b>`PeftModel.from_pretrained`:</b>\n",
        "     - By default, the adapter of the PEFT model is frozen (non-trainable).\n",
        "     - You can change this by adjusting the `is_trainable` configuration.\n",
        "\n",
        "  2. <b>`get_peft_model` function:</b>\n",
        "     - Parameters are not frozen by default.\n",
        "     - Result: you obtain a trainable PEFT model for the SFT task.\n",
        "\n",
        "  3. <b>Fine-tuning an already fine-tuned PEFT model:</b>\n",
        "     - Utilize `from_pretrained`.\n",
        "     - Set `is_trainable = True` to enable training of the previously fine-tuned model.\n",
        "    \n",
        "</details>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<details>\n",
        "  <summary style=\"list-style: none;\"><b>▶️ What is ROUGE score?</b></summary>\n",
        "  <br/>\n",
        "  ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. Some key components of ROUGE for question-answering include:\n",
        "  - ROUGE-L: Measures the longest common subsequence between the candidate and reference answers. This focuses on recall of the full text.\n",
        "  - ROUGE-1, ROUGE-2, ROUGE-SU4: Compare unigram, bigram, 4-gram overlaps between candidate and reference. Focus on recall of key parts/chunks\n",
        "\n",
        "  Higher ROUGE scores generally indicate better performance for question answering. Scores close to or above 0.70+ are considered strong.\n",
        "  When using this metric, processing like stemming, and removing stopwords can help improve the overall performance\n",
        "</details>\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "### Prompt Datasets\n",
        "\n",
        "The utilization of chat prompts during the fine-tuning of a T5 model holds crucial significance due to several inherent advantages associated with the conversational nature of such data. Here is a more detailed explanation of using chat prompts in this context:\n",
        "\n",
        "1. **Simulation of Human Interaction:** Chat prompts enable the simulation of human interactions, mirroring the dynamics of a real conversation. This approach facilitates the model's learning to generate responses that reflect the fluidity and coherence inherent in human exchanges.\n",
        "\n",
        "2. **Contextual Awareness:** Chat prompts are essential for capturing contextual nuances in conversations. Each preceding turn of speech influences the understanding and generation of responses. The use of these prompts allows the model to grasp contextual subtleties and adjust its responses accordingly.\n",
        "\n",
        "3. **Adaptation to Specific Language:** By incorporating chat prompts during fine-tuning, the model can adapt to specific languages, unique conversational styles, and even idiosyncratic expressions. This enhances the model's proficiency in generating responses that align with the particular expectations of end-users.\n",
        "\n",
        "4. **Diversity in Examples:** Conversations inherently exhibit diversity, characterized by a variety of expressions, tones, and linguistic structures. Chat prompts inject this diversity into the training process, endowing the model with the ability to handle real-world scenarios and adapt to the richness of human interactions.\n",
        "\n",
        "Using Chat prompts during the fine-tuning of a T5 model represents a potent strategy to enhance its capability in understanding and generating conversational texts. These prompts act as a bridge between training data and real-life situations, thereby strengthening the model's performance in applications such as chatbot response generation, virtual assistant systems, and other natural language processing tasks.\n",
        "\n",
        "### Model Details\n",
        "\n",
        "T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a **text-to-text** format.\n",
        "\n",
        "### Training procedure\n",
        "\n",
        "Since, T5 is a text-to-text model, the labels of the dataset are converted as follows: For each example, a sentence as been formed as \"Question sentence: \" + Answer sentence.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will gain expertise in the following areas:\n",
        "\n",
        "1. Learn how to effectively prepare datasets for training.\n",
        "2. Understand the process of fine-tuning the T5 model manually, without relying on the Trainer module.\n",
        "3. Explore the usage of accelerators to optimize model training and inference.\n",
        "4. Evaluate the performance of your model using metrics such as Rouge scores."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.021487,
          "end_time": "2024-01-19T13:29:54.206597",
          "exception": false,
          "start_time": "2024-01-19T13:29:54.18511",
          "status": "completed"
        },
        "tags": [],
        "id": "pLzLZ8niMZQA"
      },
      "id": "pLzLZ8niMZQA"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T56MTRtWM6ui",
        "outputId": "0c968e96-168e-4b0b-c93d-52b2f0182cfb"
      },
      "id": "T56MTRtWM6ui",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017461,
          "end_time": "2024-01-19T13:29:54.241388",
          "exception": false,
          "start_time": "2024-01-19T13:29:54.223927",
          "status": "completed"
        },
        "tags": [],
        "id": "8Q1kMNaVMZQD"
      },
      "id": "8Q1kMNaVMZQD"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U torch torchvision evaluate transformers datasets accelerate peft deepspeed rouge-score"
      ],
      "metadata": {
        "papermill": {
          "duration": 159.761448,
          "end_time": "2024-01-19T13:32:34.021091",
          "exception": false,
          "start_time": "2024-01-19T13:29:54.259643",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:18:51.356642Z",
          "iopub.execute_input": "2024-01-20T14:18:51.357235Z",
          "iopub.status.idle": "2024-01-20T14:21:26.051599Z",
          "shell.execute_reply.started": "2024-01-20T14:18:51.357207Z",
          "shell.execute_reply": "2024-01-20T14:21:26.050466Z"
        },
        "trusted": true,
        "id": "DQoiK8y7MZQE"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DQoiK8y7MZQE"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# Replace 'your_hub_repo_name' with the name of your repository\n",
        "hub_repo_name = \"your_hub_repo_name\"\n",
        "\n",
        "# Load the fine-tuned T5 model\n",
        "finetuned_model = T5ForConditionalGeneration.from_pretrained(hub_repo_name)"
      ],
      "metadata": {
        "id": "cTOkZDQMdpNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "d0251f37-c0f4-49f2-b701-9c80a78d0bd2"
      },
      "id": "cTOkZDQMdpNQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "your_hub_repo_name is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/your_hub_repo_name/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1402\u001b[0m             \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1262\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1675\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    370\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-66248fbd-4a865d310a27a6100a6edec9;53d60be4-1d6d-455d-a7ff-77862fcd4b8e)\n\nRepository Not Found for url: https://huggingface.co/your_hub_repo_name/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-67921f711569>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the fine-tuned T5 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfinetuned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_repo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3013\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3015\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   3016\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         ) from e\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: your_hub_repo_name is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "assert torch.cuda.is_available()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 1.74584,
          "end_time": "2024-01-19T13:32:35.785147",
          "exception": false,
          "start_time": "2024-01-19T13:32:34.039307",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:26.053659Z",
          "iopub.execute_input": "2024-01-20T14:21:26.053992Z",
          "iopub.status.idle": "2024-01-20T14:21:27.922792Z",
          "shell.execute_reply.started": "2024-01-20T14:21:26.053965Z",
          "shell.execute_reply": "2024-01-20T14:21:27.921719Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "vXxjGE5PMZQF",
        "outputId": "39656901-5991-422e-e223-84b19ee3cc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5ae226c784f9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "id": "vXxjGE5PMZQF"
    },
    {
      "cell_type": "code",
      "source": [
        "###### General ######\n",
        "import os\n",
        "import gc\n",
        "import platform\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###### Torch ######\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "###### Hugging face ######\n",
        "\n",
        "# Hub\n",
        "# --\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Dataset\n",
        "# --\n",
        "from datasets import Dataset, DatasetDict, load_dataset, load_metric\n",
        "import datasets\n",
        "\n",
        "# Transformers\n",
        "# --\n",
        "from transformers import pipeline, T5ForConditionalGeneration, AutoTokenizer, AutoConfig, default_data_collator, get_linear_schedule_with_warmup, DataCollatorForSeq2Seq, set_seed\n",
        "import transformers\n",
        "\n",
        "# Perf\n",
        "# --\n",
        "from peft import LoraConfig, TaskType, get_peft_model, get_peft_model_state_dict, PeftModel\n",
        "from peft.utils.other import fsdp_auto_wrap_policy\n",
        "from peft import PeftConfig\n",
        "\n",
        "# Accelerator\n",
        "# --\n",
        "from accelerate import Accelerator\n",
        "\n",
        "# Rouge score\n",
        "# --\n",
        "import evaluate\n",
        "import nltk\n",
        "\n",
        "###### Kaggle ######\n",
        "\n",
        "# Kaggle\n",
        "# --\n",
        "from kaggle_secrets import UserSecretsClient"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 17.070175,
          "end_time": "2024-01-19T13:32:52.873096",
          "exception": false,
          "start_time": "2024-01-19T13:32:35.802921",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:27.92595Z",
          "iopub.execute_input": "2024-01-20T14:21:27.926922Z",
          "iopub.status.idle": "2024-01-20T14:21:45.520307Z",
          "shell.execute_reply.started": "2024-01-20T14:21:27.926863Z",
          "shell.execute_reply": "2024-01-20T14:21:45.519358Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Ck3QHMNxMZQG",
        "outputId": "eb7589e3-931b-4fb5-fb69-1a79964cf156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'kaggle_secrets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-de80c1154d99>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# --\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle_secrets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_secrets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "id": "Ck3QHMNxMZQG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Config"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017451,
          "end_time": "2024-01-19T13:32:52.908489",
          "exception": false,
          "start_time": "2024-01-19T13:32:52.891038",
          "status": "completed"
        },
        "tags": [],
        "id": "S0KiB-F2MZQH"
      },
      "id": "S0KiB-F2MZQH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging face\n",
        "# ---\n",
        "hub_repo_name=\"YanSte/t5_large_fine_tuning_lora_question_answering_hc3_and_chatgpt_prompts\"\n",
        "\n",
        "# General\n",
        "# ---\n",
        "cache_dir = \"./cache\"\n",
        "seed = 42\n",
        "\n",
        "# Model\n",
        "# ---\n",
        "model_name_or_path = \"google/flan-t5-large\"#\"google/flan-t5-xxl\"\n",
        "\n",
        "# Data formatting\n",
        "# ---\n",
        "prefix = \"Answer this question: \"# We prefix our task\n",
        "\n",
        "# Data formatting and tokenization\n",
        "# ---\n",
        "tokenizer_input_max_tokens = 256\n",
        "tokenizer_output_max_tokens = 256\n",
        "tokenizer_num_proc=16\n",
        "\n",
        "# DataLoader\n",
        "# ---\n",
        "data_loader_batch_size = 4\n",
        "\n",
        "# Lora\n",
        "# ---\n",
        "lora_task_type=TaskType.SEQ_2_SEQ_LM\n",
        "lora_inference_mode=False\n",
        "lora_r=8\n",
        "lora_alpha=32\n",
        "lora_dropout=0.1\n",
        "\n",
        "# Model\n",
        "# ---\n",
        "lr = 1e-4\n",
        "num_epochs = 3\n",
        "\n",
        "def get_peft_model_name_or_path(model_name_or_path, peft_config):\n",
        "    return f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\"/\", \"_\")\n",
        "\n",
        "def get_optimizer(model, lr):\n",
        "    return torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# Pipeline\n",
        "# ---\n",
        "pipeline_task = \"text2text-generation\"\n",
        "pipeline_min_length=20\n",
        "pipeline_temperature=0.3\n",
        "pipeline_max_length=256"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031283,
          "end_time": "2024-01-19T13:32:52.957342",
          "exception": false,
          "start_time": "2024-01-19T13:32:52.926059",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.522443Z",
          "iopub.execute_input": "2024-01-20T14:21:45.524325Z",
          "iopub.status.idle": "2024-01-20T14:21:45.532861Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.524289Z",
          "shell.execute_reply": "2024-01-20T14:21:45.531737Z"
        },
        "trusted": true,
        "id": "GcVQxeYWMZQI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "GcVQxeYWMZQI"
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=UserSecretsClient().get_secret(\"HUGGINGFACEHUB_API_TOKEN\"))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.260467,
          "end_time": "2024-01-19T13:32:53.236001",
          "exception": false,
          "start_time": "2024-01-19T13:32:52.975534",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.534041Z",
          "iopub.execute_input": "2024-01-20T14:21:45.534433Z",
          "iopub.status.idle": "2024-01-20T14:21:45.903396Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.534398Z",
          "shell.execute_reply": "2024-01-20T14:21:45.902406Z"
        },
        "trusted": true,
        "id": "aHRj7XHsMZQI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "58a452ac-d78e-47bb-980f-730b98b25097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'UserSecretsClient' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-76bac815b6a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HUGGINGFACEHUB_API_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'UserSecretsClient' is not defined"
          ]
        }
      ],
      "id": "aHRj7XHsMZQI"
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1024\""
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:32:53.322789Z",
          "iopub.status.busy": "2024-01-19T13:32:53.32202Z",
          "iopub.status.idle": "2024-01-19T13:32:53.326134Z",
          "shell.execute_reply": "2024-01-19T13:32:53.325285Z"
        },
        "papermill": {
          "duration": 0.026753,
          "end_time": "2024-01-19T13:32:53.328033",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.30128",
          "status": "completed"
        },
        "tags": [],
        "id": "iFBeTnr8MZQK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iFBeTnr8MZQK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017471,
          "end_time": "2024-01-19T13:32:53.363473",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.346002",
          "status": "completed"
        },
        "tags": [],
        "id": "Zl24_mgSMZQM"
      },
      "id": "Zl24_mgSMZQM"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_column', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_seq_items', None)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "pd.set_option('expand_frame_repr', True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026097,
          "end_time": "2024-01-19T13:32:53.406995",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.380898",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.904824Z",
          "iopub.execute_input": "2024-01-20T14:21:45.905533Z",
          "iopub.status.idle": "2024-01-20T14:21:45.91186Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.905496Z",
          "shell.execute_reply": "2024-01-20T14:21:45.910941Z"
        },
        "trusted": true,
        "id": "hjbXz-Z8MZQN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hjbXz-Z8MZQN"
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.0278,
          "end_time": "2024-01-19T13:32:53.452761",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.424961",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.912942Z",
          "iopub.execute_input": "2024-01-20T14:21:45.91324Z",
          "iopub.status.idle": "2024-01-20T14:21:45.92512Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.913215Z",
          "shell.execute_reply": "2024-01-20T14:21:45.924245Z"
        },
        "trusted": true,
        "id": "kbchL6yyMZQN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kbchL6yyMZQN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accelerator"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018312,
          "end_time": "2024-01-19T13:32:53.489774",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.471462",
          "status": "completed"
        },
        "tags": [],
        "id": "oMJEtZcrMZQO"
      },
      "id": "oMJEtZcrMZQO"
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator = Accelerator()\n",
        "\n",
        "# Or\n",
        "# Initialize accelerator with config from configs/accelerate_ds_z3.yaml\n",
        "# accelerator = (\n",
        "#     Accelerator(log_with=args.report_to, logging_dir=args.output_dir) if args.with_tracking else Accelerator()\n",
        "# )"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.028855,
          "end_time": "2024-01-19T13:32:53.538471",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.509616",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.926322Z",
          "iopub.execute_input": "2024-01-20T14:21:45.92663Z",
          "iopub.status.idle": "2024-01-20T14:21:45.936312Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.926605Z",
          "shell.execute_reply": "2024-01-20T14:21:45.935376Z"
        },
        "trusted": true,
        "id": "xK1hTXKgMZQO"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xK1hTXKgMZQO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018422,
          "end_time": "2024-01-19T13:32:53.580578",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.562156",
          "status": "completed"
        },
        "tags": [],
        "id": "xaqR6048MZQP"
      },
      "id": "xaqR6048MZQP"
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.utils.logging.set_verbosity_error()\n",
        "transformers.utils.logging.set_verbosity_error()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.025587,
          "end_time": "2024-01-19T13:32:53.625109",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.599522",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.937668Z",
          "iopub.execute_input": "2024-01-20T14:21:45.938079Z",
          "iopub.status.idle": "2024-01-20T14:21:45.945055Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.938043Z",
          "shell.execute_reply": "2024-01-20T14:21:45.944138Z"
        },
        "trusted": true,
        "id": "gc6v9UcXMZQP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "gc6v9UcXMZQP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rouge metric"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018459,
          "end_time": "2024-01-19T13:32:53.661523",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.643064",
          "status": "completed"
        },
        "tags": [],
        "id": "ykDWt87PMZQQ"
      },
      "id": "ykDWt87PMZQQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK punkt tokenizer\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "# Load ROUGE metric\n",
        "rouge_metric = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.64672,
          "end_time": "2024-01-19T13:32:54.326507",
          "exception": false,
          "start_time": "2024-01-19T13:32:53.679787",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:45.948513Z",
          "iopub.execute_input": "2024-01-20T14:21:45.949384Z",
          "iopub.status.idle": "2024-01-20T14:21:46.910276Z",
          "shell.execute_reply.started": "2024-01-20T14:21:45.949356Z",
          "shell.execute_reply": "2024-01-20T14:21:46.909443Z"
        },
        "trusted": true,
        "id": "vBGV3kIIMZQQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5e5fcfd23fb44aa9a5e64e9aa0aa01c4",
            "5067c9ad62104c389c04a67fd0bacf48",
            "e14c53ea06e24a1db4d3ac1378f13ec9",
            "fac13b79a30141afae7b77090347cb62",
            "f994ed4d20ed41a68c347d7b2bae8d85",
            "e79f5c166a014048998dd2a2b8148558",
            "c87738656c1940699da500d6c667a79d",
            "a9d40e4eccd54621925838bd1d734eb5",
            "cbec0507205c483681568ce064d035e4",
            "9f8f79bfbceb46af863f132de18f9d00",
            "0d7e1336649a42aaa378d1b032ab1864"
          ]
        },
        "outputId": "13409979-c89a-48bf-f27b-460c90e6521d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e5fcfd23fb44aa9a5e64e9aa0aa01c4"
            }
          },
          "metadata": {}
        }
      ],
      "id": "vBGV3kIIMZQQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Methods"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017988,
          "end_time": "2024-01-19T13:32:54.362725",
          "exception": false,
          "start_time": "2024-01-19T13:32:54.344737",
          "status": "completed"
        },
        "tags": [],
        "id": "5TXr0li5MZQR"
      },
      "id": "5TXr0li5MZQR"
    },
    {
      "cell_type": "code",
      "source": [
        "def accelerator_print_sep(accelerator=accelerator):\n",
        "    sep = \"#\" * 12\n",
        "    accelerator.print(sep)\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory by emptying the cache and collecting garbage.\"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def print_system_specs():\n",
        "    # Check if CUDA is available\n",
        "    is_cuda_available = torch.cuda.is_available()\n",
        "    print(\"CUDA Available:\", is_cuda_available)\n",
        "# Get the number of available CUDA devices\n",
        "    num_cuda_devices = torch.cuda.device_count()\n",
        "    print(\"Number of CUDA devices:\", num_cuda_devices)\n",
        "    if is_cuda_available:\n",
        "        for i in range(num_cuda_devices):\n",
        "            # Get CUDA device properties\n",
        "            device = torch.device('cuda', i)\n",
        "            print(f\"--- CUDA Device {i} ---\")\n",
        "            print(\"Name:\", torch.cuda.get_device_name(i))\n",
        "            print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
        "            print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
        "    # Get CPU information\n",
        "    print(\"--- CPU Information ---\")\n",
        "    print(\"Processor:\", platform.processor())\n",
        "    print(\"System:\", platform.system(), platform.release())\n",
        "    print(\"Python Version:\", platform.python_version())"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.029139,
          "end_time": "2024-01-19T13:32:54.409218",
          "exception": false,
          "start_time": "2024-01-19T13:32:54.380079",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:46.911328Z",
          "iopub.execute_input": "2024-01-20T14:21:46.911582Z",
          "iopub.status.idle": "2024-01-20T14:21:46.920324Z",
          "shell.execute_reply.started": "2024-01-20T14:21:46.91156Z",
          "shell.execute_reply": "2024-01-20T14:21:46.919265Z"
        },
        "trusted": true,
        "id": "rsh31gC-MZQR"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rsh31gC-MZQR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Specs"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017717,
          "end_time": "2024-01-19T13:32:54.444547",
          "exception": false,
          "start_time": "2024-01-19T13:32:54.42683",
          "status": "completed"
        },
        "tags": [],
        "id": "g_dwKf7eMZQS"
      },
      "id": "g_dwKf7eMZQS"
    },
    {
      "cell_type": "code",
      "source": [
        "print_system_specs()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026633,
          "end_time": "2024-01-19T13:32:54.489381",
          "exception": false,
          "start_time": "2024-01-19T13:32:54.462748",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:46.921723Z",
          "iopub.execute_input": "2024-01-20T14:21:46.9221Z",
          "iopub.status.idle": "2024-01-20T14:21:47.310442Z",
          "shell.execute_reply.started": "2024-01-20T14:21:46.922064Z",
          "shell.execute_reply": "2024-01-20T14:21:47.309433Z"
        },
        "trusted": true,
        "id": "UDfK0e33MZQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c002a0-e6a9-4e4c-f387-dd17e4a0c519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: False\n",
            "Number of CUDA devices: 0\n",
            "--- CPU Information ---\n",
            "Processor: x86_64\n",
            "System: Linux 6.1.58+\n",
            "Python Version: 3.10.12\n"
          ]
        }
      ],
      "id": "UDfK0e33MZQS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>2 <span style='color:#78D118'>|</span> Fine-Tuning</b>\n",
        "\n",
        "### Step 1 - Data Preparation\n",
        "\n",
        "The first step of the fine-tuning process is to identify a specific task and supporting dataset.\n",
        "\n",
        "We will use two datasets:\n",
        "\n",
        "[Hello-SimpleAI/HC3](https://huggingface.co/datasets/Hello-SimpleAI/HC3?source=post_page-----d7817b77fac0--------------------------------)\n",
        "\n",
        "and\n",
        "\n",
        "[MohamedRashad/ChatGPT-prompts](https://huggingface.co/datasets/MohamedRashad/ChatGPT-prompts?source=post_page-----d7817b77fac0--------------------------------)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018584,
          "end_time": "2024-01-19T13:32:54.527852",
          "exception": false,
          "start_time": "2024-01-19T13:32:54.509268",
          "status": "completed"
        },
        "tags": [],
        "id": "drQmmJXgMZQT"
      },
      "id": "drQmmJXgMZQT"
    },
    {
      "cell_type": "code",
      "source": [
        "hello_dataset = load_dataset(\"Hello-SimpleAI/HC3\", name=\"all\")\n",
        "hc3_dataset = load_dataset(\"MohamedRashad/ChatGPT-prompts\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 4.083855,
          "end_time": "2024-01-19T13:32:58.629809",
          "exception": false,
          "start_time": "2024-01-19T13:32:54.545954",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:47.311552Z",
          "iopub.execute_input": "2024-01-20T14:21:47.311866Z",
          "iopub.status.idle": "2024-01-20T14:21:55.662136Z",
          "shell.execute_reply.started": "2024-01-20T14:21:47.311838Z",
          "shell.execute_reply": "2024-01-20T14:21:55.661159Z"
        },
        "trusted": true,
        "id": "9Ml15e3WMZQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "fb2b69ad55db4e39ba1469a8f5ffffc0",
            "d569eee6a06f462e8d68ec163e955140",
            "a3b99937baf042ec9398f59b5c295a2e",
            "6e4cf55605d64c1f8ddaf84226f3ce0c",
            "83222dc452f94d53a9d2e8491044d8ab",
            "d481d3a098ac49b5bdc29729d9a2893c",
            "9916108906df4e219b5a18147bb80d35",
            "6a306d92b73d44229739cc91cc31604e",
            "742b46c4f34644f9bdf4ed0d868ff1f0",
            "4bbe782d605c4bd5abe91949b39e354a",
            "16bb356e37184052bbfd883dcf46bb1d",
            "7bff284fb3dc4f4c869e2b6474b09aaf",
            "27f616fa2fb046e4942d3fd2346ad4ee",
            "f620a98fecc74cd187265a9b49569c92",
            "bc1c185f0a074bc7a1ca1bd9f7c1601b",
            "15933885883140cdbb3029db302fbe45",
            "76ed372f1c6b4ed4a86b950bd78fc5e3",
            "072671e7fa9a49adafa8a454ee57c7ce",
            "04e7bba8af26463986c731d2db65e75f",
            "f73da608d70648968b602b9d2cb71991",
            "f4f875e7902641bda9f5ab0566ef4d3c",
            "18e3929fffbc48c892b6828245b3f8b8",
            "2ab64792e47a48f8accf715e27aa0476",
            "8aeb664adfb3488d81b09c97781e61c7",
            "18b16056803c48d99c13a1919a4077e3",
            "c1f9f69a22544e73b945064c694f5fc2",
            "85f89c9515e44c8480e70e68b3f3ec72",
            "3c86ef1fdb1a49b3b8671de1b2a97820",
            "9432acf5ca564c98972d26ce196b8ce3",
            "78de475054244fec900aa07981540c77",
            "5303b9f5c68649a294a7d67038a4285a",
            "71280fc671cf42e8a687806bb9b9252a",
            "61e0935a08454625afac1dbad89dd561",
            "afc703dcc0ff4927b33114d1c5230a6f",
            "5c15b2134567472783d07f2e7c675856",
            "b38cc735b96149d7874cfce1c6397a00",
            "ab13006a2f7d4a10a6c43d6a4aa9a3ff",
            "8f9b9d335a154cd2a23db931f19f2cd8",
            "dea025339aed4a5e8b4b4ebc94accc28",
            "ee2f50f2d9814d579a7164cef39ca223",
            "3327140dc6d9489fb5b3f2f2c74e71cd",
            "d0acadc1d67f4456a631e9df98d1789a",
            "3339fac297f74999b6e9239fbb19b020",
            "f14c31f8a28d4ccebeba8ba13ca44940",
            "b13b71b3c5e04692a7fb7be72132861f",
            "7276cd7f393f4e5691c5c6aadb670712",
            "004f2949be1d4a3685d9f649e7197bec",
            "858f14d5abb74d079a2e13cf9e25e250",
            "c6b896c7670145919c4d3ee889cc7f68",
            "eb386a0842c74dadbb6298eaabcbb888",
            "e9017325da6d4fde8610671abc4e0163",
            "9f5e2ad69ee642729da3bb9051a22c79",
            "0b45647be4e84f62b7306d7303e1fc12",
            "c93e86a68ee944cea19be9093db0cb89",
            "b6d8080cc1684fd68c9e75d135469cd8"
          ]
        },
        "outputId": "855403db-0755-401f-ff79-ac1ef9981bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/39.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb2b69ad55db4e39ba1469a8f5ffffc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/24322 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bff284fb3dc4f4c869e2b6474b09aaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/404 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab64792e47a48f8accf715e27aa0476"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/422k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afc703dcc0ff4927b33114d1c5230a6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/360 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b13b71b3c5e04692a7fb7be72132861f"
            }
          },
          "metadata": {}
        }
      ],
      "id": "9Ml15e3WMZQT"
    },
    {
      "cell_type": "code",
      "source": [
        "hc3_dataset"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.030628,
          "end_time": "2024-01-19T13:32:58.680032",
          "exception": false,
          "start_time": "2024-01-19T13:32:58.649404",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T11:49:15.675005Z",
          "iopub.execute_input": "2024-01-20T11:49:15.675393Z",
          "iopub.status.idle": "2024-01-20T11:49:15.682245Z",
          "shell.execute_reply.started": "2024-01-20T11:49:15.675357Z",
          "shell.execute_reply": "2024-01-20T11:49:15.6813Z"
        },
        "trusted": true,
        "id": "j3KlwnlOMZQT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "j3KlwnlOMZQT"
    },
    {
      "cell_type": "code",
      "source": [
        "hello_dataset"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.027682,
          "end_time": "2024-01-19T13:32:58.727154",
          "exception": false,
          "start_time": "2024-01-19T13:32:58.699472",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T11:49:15.683419Z",
          "iopub.execute_input": "2024-01-20T11:49:15.683732Z",
          "iopub.status.idle": "2024-01-20T11:49:15.773014Z",
          "shell.execute_reply.started": "2024-01-20T11:49:15.683705Z",
          "shell.execute_reply": "2024-01-20T11:49:15.772Z"
        },
        "trusted": true,
        "id": "NNa6JtorMZQU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NNa6JtorMZQU"
    },
    {
      "cell_type": "code",
      "source": [
        "hello_df, hc3_df = pd.DataFrame(hello_dataset['train']), pd.DataFrame(hc3_dataset['train'])\n",
        "\n",
        "# Test\n",
        "# ---\n",
        "#hello_df, hc3_df = hello_df.iloc[:10], hc3_df.iloc[:10]"
      ],
      "metadata": {
        "papermill": {
          "duration": 2.144205,
          "end_time": "2024-01-19T13:33:00.890933",
          "exception": false,
          "start_time": "2024-01-19T13:32:58.746728",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:55.663527Z",
          "iopub.execute_input": "2024-01-20T14:21:55.663934Z",
          "iopub.status.idle": "2024-01-20T14:21:57.87499Z",
          "shell.execute_reply.started": "2024-01-20T14:21:55.66387Z",
          "shell.execute_reply": "2024-01-20T14:21:57.87379Z"
        },
        "trusted": true,
        "id": "4c_hyvD-MZQU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4c_hyvD-MZQU"
    },
    {
      "cell_type": "code",
      "source": [
        "questions, reference_answers = [], []\n",
        "\n",
        "# Process Hello DataFrame\n",
        "for _, row in hello_df.iterrows():\n",
        "\n",
        "    for reference in row[\"human_answers\"]:\n",
        "        questions.append(row[\"question\"])\n",
        "        reference_answers.append(reference)\n",
        "\n",
        "    for reference in row[\"chatgpt_answers\"]:\n",
        "        questions.append(row[\"question\"])\n",
        "        reference_answers.append(reference)\n",
        "\n",
        "# Process Hc3 DataFrame\n",
        "for _, row in hc3_df.iterrows():\n",
        "    human_prompt = row[\"human_prompt\"]\n",
        "    chatgpt_response = row[\"chatgpt_response\"]\n",
        "    questions.append(human_prompt)\n",
        "    reference_answers.append(chatgpt_response)\n",
        "\n",
        "# Create a new DataFrame\n",
        "df = pd.DataFrame()\n",
        "df[\"question\"] = questions\n",
        "df[\"answer\"] = reference_answers\n",
        "\n",
        "# Save to CSV file\n",
        "df.to_csv(\"./train.csv\", index=False)"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.75296,
          "end_time": "2024-01-19T13:33:06.663397",
          "exception": false,
          "start_time": "2024-01-19T13:33:00.910437",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:21:57.87649Z",
          "iopub.execute_input": "2024-01-20T14:21:57.87688Z",
          "iopub.status.idle": "2024-01-20T14:22:03.618955Z",
          "shell.execute_reply.started": "2024-01-20T14:21:57.876849Z",
          "shell.execute_reply": "2024-01-20T14:22:03.617908Z"
        },
        "trusted": true,
        "id": "mQ4-cHpsMZQU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "mQ4-cHpsMZQU"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.038561,
          "end_time": "2024-01-19T13:33:06.723636",
          "exception": false,
          "start_time": "2024-01-19T13:33:06.685075",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:22:03.620283Z",
          "iopub.execute_input": "2024-01-20T14:22:03.620598Z",
          "iopub.status.idle": "2024-01-20T14:22:03.634649Z",
          "shell.execute_reply.started": "2024-01-20T14:22:03.620573Z",
          "shell.execute_reply": "2024-01-20T14:22:03.633693Z"
        },
        "trusted": true,
        "id": "2Uqm9kHGMZQU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "2Uqm9kHGMZQU"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(df, split='train')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:06.767925Z",
          "iopub.status.busy": "2024-01-19T13:33:06.767594Z",
          "iopub.status.idle": "2024-01-19T13:33:07.395871Z",
          "shell.execute_reply": "2024-01-19T13:33:07.395062Z"
        },
        "papermill": {
          "duration": 0.65307,
          "end_time": "2024-01-19T13:33:07.398367",
          "exception": false,
          "start_time": "2024-01-19T13:33:06.745297",
          "status": "completed"
        },
        "tags": [],
        "id": "ALZdvlKtMZQV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ALZdvlKtMZQV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data is acquired, it is split into training and testing datasets, respectively, at the proportion of 70% and 30%, and this is achieved using the train_test_split function."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023125,
          "end_time": "2024-01-19T13:33:07.442659",
          "exception": false,
          "start_time": "2024-01-19T13:33:07.419534",
          "status": "completed"
        },
        "tags": [],
        "id": "jxn6EP40MZQV"
      },
      "id": "jxn6EP40MZQV"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(shuffle=True, test_size=0.3, seed=seed)\n",
        "test_ds = dataset.pop(\"test\")\n",
        "dataset[\"validation\"] = test_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:07.488297Z",
          "iopub.status.busy": "2024-01-19T13:33:07.487957Z",
          "iopub.status.idle": "2024-01-19T13:33:07.52986Z",
          "shell.execute_reply": "2024-01-19T13:33:07.528947Z"
        },
        "papermill": {
          "duration": 0.067113,
          "end_time": "2024-01-19T13:33:07.532016",
          "exception": false,
          "start_time": "2024-01-19T13:33:07.464903",
          "status": "completed"
        },
        "tags": [],
        "id": "fbmaGTgPMZQV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fbmaGTgPMZQV"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:07.578922Z",
          "iopub.status.busy": "2024-01-19T13:33:07.578591Z",
          "iopub.status.idle": "2024-01-19T13:33:07.584385Z",
          "shell.execute_reply": "2024-01-19T13:33:07.583503Z"
        },
        "papermill": {
          "duration": 0.031107,
          "end_time": "2024-01-19T13:33:07.586586",
          "exception": false,
          "start_time": "2024-01-19T13:33:07.555479",
          "status": "completed"
        },
        "tags": [],
        "id": "CuEVnwozMZQV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CuEVnwozMZQV"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dataset[:15]).head(15)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:07.631816Z",
          "iopub.status.busy": "2024-01-19T13:33:07.631503Z",
          "iopub.status.idle": "2024-01-19T13:33:07.645814Z",
          "shell.execute_reply": "2024-01-19T13:33:07.644898Z"
        },
        "papermill": {
          "duration": 0.039307,
          "end_time": "2024-01-19T13:33:07.647722",
          "exception": false,
          "start_time": "2024-01-19T13:33:07.608415",
          "status": "completed"
        },
        "tags": [],
        "id": "mNr0YPwGMZQV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "mNr0YPwGMZQV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Model and Tokenizer initialization\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020914,
          "end_time": "2024-01-19T13:33:07.689899",
          "exception": false,
          "start_time": "2024-01-19T13:33:07.668985",
          "status": "completed"
        },
        "tags": [],
        "id": "EcEZ9JMYMZQW"
      },
      "id": "EcEZ9JMYMZQW"
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:07.735852Z",
          "iopub.status.busy": "2024-01-19T13:33:07.735537Z",
          "iopub.status.idle": "2024-01-19T13:33:56.951404Z",
          "shell.execute_reply": "2024-01-19T13:33:56.950266Z"
        },
        "papermill": {
          "duration": 49.242135,
          "end_time": "2024-01-19T13:33:56.953906",
          "exception": false,
          "start_time": "2024-01-19T13:33:07.711771",
          "status": "completed"
        },
        "tags": [],
        "id": "47svNJS8MZQW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "47svNJS8MZQW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - Data formatting and tokenization\n",
        "\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.021906,
          "end_time": "2024-01-19T13:33:56.997911",
          "exception": false,
          "start_time": "2024-01-19T13:33:56.976005",
          "status": "completed"
        },
        "tags": [],
        "id": "H34J9Ex0MZQW"
      },
      "id": "H34J9Ex0MZQW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a significant amount of data in both training and testing datasets for the fine-tuning process.\n",
        "\n",
        "But, before that we need to process the data to fit the fine-tuning format.\n",
        "\n",
        "During the inference mode, the process of calling the model will be in this format:\n",
        "```\n",
        "“Answer this question: <USER_QUESTION>”\n",
        "```\n",
        "Where the ```<USER_QUESTION>``` is the question the user would like the answer about. To achieve that functionality, we need to format the training data by prefixing the task with the string ```“Answer this question”``` and this is done with the preprocess_function function below.\n",
        "\n",
        "In addition to the formatting, the function also applies the tokenization of the inputs and outputs using the tokenizer function.\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022398,
          "end_time": "2024-01-19T13:33:57.042094",
          "exception": false,
          "start_time": "2024-01-19T13:33:57.019696",
          "status": "completed"
        },
        "tags": [],
        "id": "mYZpXLHNMZQW"
      },
      "id": "mYZpXLHNMZQW"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tokenize(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"question\"]]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=tokenizer_input_max_tokens,\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    labels = tokenizer(\n",
        "        examples[\"answer\"],\n",
        "        max_length=tokenizer_output_max_tokens,\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:57.086787Z",
          "iopub.status.busy": "2024-01-19T13:33:57.086438Z",
          "iopub.status.idle": "2024-01-19T13:33:57.09233Z",
          "shell.execute_reply": "2024-01-19T13:33:57.091538Z"
        },
        "papermill": {
          "duration": 0.03036,
          "end_time": "2024-01-19T13:33:57.094272",
          "exception": false,
          "start_time": "2024-01-19T13:33:57.063912",
          "status": "completed"
        },
        "tags": [],
        "id": "PuXezH2YMZQh"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PuXezH2YMZQh"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "qdar9l6yY1CL"
      },
      "id": "qdar9l6yY1CL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_datasets = dataset.map(\n",
        "    preprocess_tokenize,\n",
        "    batched=True,\n",
        "    num_proc=1,  # Change this line to disable multiprocessing\n",
        "    # or use num_proc=None\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "del dataset\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"validation\"]\n",
        "\n",
        "model, optimizer = accelerator.prepare(your_model, your_optimizer)"
      ],
      "metadata": {
        "id": "XDcyXaORUXBz"
      },
      "id": "XDcyXaORUXBz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with accelerator.main_process_first():\n",
        "    processed_datasets = dataset.map(\n",
        "        preprocess_tokenize,\n",
        "        batched=True,\n",
        "        num_proc=tokenizer_num_proc,\n",
        "        remove_columns=dataset[\"train\"].column_names,\n",
        "        load_from_cache_file=False,\n",
        "        desc=\"Running tokenizer on dataset\",\n",
        "    )\n",
        "\n",
        "\n",
        "del dataset\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"validation\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:33:57.138148Z",
          "iopub.status.busy": "2024-01-19T13:33:57.137856Z",
          "iopub.status.idle": "2024-01-19T13:34:50.841079Z",
          "shell.execute_reply": "2024-01-19T13:34:50.839939Z"
        },
        "papermill": {
          "duration": 53.727935,
          "end_time": "2024-01-19T13:34:50.843695",
          "exception": false,
          "start_time": "2024-01-19T13:33:57.11576",
          "status": "completed"
        },
        "tags": [],
        "id": "jCaWQv0lMZQi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jCaWQv0lMZQi"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:50.890388Z",
          "iopub.status.busy": "2024-01-19T13:34:50.890017Z",
          "iopub.status.idle": "2024-01-19T13:34:50.896376Z",
          "shell.execute_reply": "2024-01-19T13:34:50.895496Z"
        },
        "papermill": {
          "duration": 0.031571,
          "end_time": "2024-01-19T13:34:50.898461",
          "exception": false,
          "start_time": "2024-01-19T13:34:50.86689",
          "status": "completed"
        },
        "tags": [],
        "id": "HH_DVfN4MZQi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HH_DVfN4MZQi"
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:50.94571Z",
          "iopub.status.busy": "2024-01-19T13:34:50.945329Z",
          "iopub.status.idle": "2024-01-19T13:34:50.95098Z",
          "shell.execute_reply": "2024-01-19T13:34:50.950113Z"
        },
        "papermill": {
          "duration": 0.031984,
          "end_time": "2024-01-19T13:34:50.952878",
          "exception": false,
          "start_time": "2024-01-19T13:34:50.920894",
          "status": "completed"
        },
        "tags": [],
        "id": "r48pkDlbMZQi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "r48pkDlbMZQi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 - DataLoader"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023375,
          "end_time": "2024-01-19T13:34:50.998871",
          "exception": false,
          "start_time": "2024-01-19T13:34:50.975496",
          "status": "completed"
        },
        "tags": [],
        "id": "9kAn-EU-MZQj"
      },
      "id": "9kAn-EU-MZQj"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=data_loader_batch_size,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=data_loader_batch_size,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:51.051131Z",
          "iopub.status.busy": "2024-01-19T13:34:51.05038Z",
          "iopub.status.idle": "2024-01-19T13:34:51.056868Z",
          "shell.execute_reply": "2024-01-19T13:34:51.055881Z"
        },
        "papermill": {
          "duration": 0.035211,
          "end_time": "2024-01-19T13:34:51.059121",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.02391",
          "status": "completed"
        },
        "tags": [],
        "id": "nl-rmNqxMZQj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nl-rmNqxMZQj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cleaning Memory"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023351,
          "end_time": "2024-01-19T13:34:51.108153",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.084802",
          "status": "completed"
        },
        "tags": [],
        "id": "omFgGin6MZQj"
      },
      "id": "omFgGin6MZQj"
    },
    {
      "cell_type": "code",
      "source": [
        "clear_gpu_memory()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:51.156913Z",
          "iopub.status.busy": "2024-01-19T13:34:51.15603Z",
          "iopub.status.idle": "2024-01-19T13:34:51.557312Z",
          "shell.execute_reply": "2024-01-19T13:34:51.556268Z"
        },
        "papermill": {
          "duration": 0.428628,
          "end_time": "2024-01-19T13:34:51.559346",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.130718",
          "status": "completed"
        },
        "tags": [],
        "id": "WNVL-t1rMZQj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "WNVL-t1rMZQj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 - Lora\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022704,
          "end_time": "2024-01-19T13:34:51.605399",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.582695",
          "status": "completed"
        },
        "tags": [],
        "id": "wYwfZRLkMZQj"
      },
      "id": "wYwfZRLkMZQj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of each argument for the `LoraConfig` class in the `peft` module:\n",
        "\n",
        "1. **`r` (int, default=8):**  \n",
        "   Dimension/Rank of the LoRA decomposition. For each layer to be trained, the weight update matrix \\( \\Delta W \\) of dimension \\( d \\times k \\) is represented by a low-rank decomposition \\( BA \\), where \\( B \\) is a \\( d \\times r \\) matrix and \\( A \\) is an \\( r \\times k \\) matrix. The rank of the decomposition \\( r \\) is typically much smaller than the minimum between \\( d \\) and \\( k \\). The default value for \\( r \\) is 8.\n",
        "   \n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EnUd1eXLvXCxRZj9NW2BeA.png\" alt=\"Learning\" width=\"50%\">\n",
        "\n",
        "2. **`lora_alpha` (float, default=8):**  \n",
        "   Alpha parameter for LoRA scaling. According to the LoRA paper, \\( \\Delta W \\) is scaled by \\( \\alpha / r \\), where \\( \\alpha \\) is a constant. When optimizing with Adam, setting \\( \\alpha \\) is roughly the same as setting the learning rate if initialization has been appropriately scaled. The default value for \\( \\alpha \\) is 8.\n",
        "\n",
        "3. **`target_modules` (list of str, default=None):**  \n",
        "   Modules to apply LoRA on. You can select specific modules to fine-tune. This is a list of module names such as \"q\" (query module) and \"v\" (value module). The default is `None`, which means LoRA will be applied to all layers of the model.\n",
        "\n",
        "4. **`lora_dropout` (float, default=0.01):**  \n",
        "   Dropout rate for LoRA weights. This parameter controls the probability of zeroing out elements in the \\( B \\) matrix during training, helping to regularize the model. The default value is 0.01.\n",
        "\n",
        "5. **`bias` (str, default=\"none\"):**  \n",
        "   Bias can be ‘none’, ‘all’ or ‘lora_only’. If ‘all’ or ‘lora_only’, the corresponding biases will be updated during training. Even when disabling the adapters, the model will not produce the same output as the base model would have without adaptation. The default is None.\n",
        "\n",
        "6. **`task_type` (str, default=\"SEQ_2_SEQ_LM\"):**  \n",
        "   Task type. This is the type of task for which the model is fine-tuned. Possible options include \"SEQ_2_SEQ_LM\" (Sequence-to-Sequence Language Model) and other specific task types. The default is \"SEQ_2_SEQ_LM\".\n",
        "\n",
        "These parameters allow customization of the LoRA fine-tuning behavior to fit specific application needs."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02166,
          "end_time": "2024-01-19T13:34:51.649162",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.627502",
          "status": "completed"
        },
        "tags": [],
        "id": "5r7ZXtpDMZQj"
      },
      "id": "5r7ZXtpDMZQj"
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    task_type=lora_task_type,\n",
        "    inference_mode=lora_inference_mode\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:51.698107Z",
          "iopub.status.busy": "2024-01-19T13:34:51.697321Z",
          "iopub.status.idle": "2024-01-19T13:34:51.702569Z",
          "shell.execute_reply": "2024-01-19T13:34:51.701634Z"
        },
        "papermill": {
          "duration": 0.032347,
          "end_time": "2024-01-19T13:34:51.70456",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.672213",
          "status": "completed"
        },
        "tags": [],
        "id": "YOtmzjomMZQk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YOtmzjomMZQk"
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "accelerator_print_sep()\n",
        "accelerator.print(model.print_trainable_parameters())\n",
        "accelerator_print_sep()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:51.753711Z",
          "iopub.status.busy": "2024-01-19T13:34:51.752819Z",
          "iopub.status.idle": "2024-01-19T13:34:52.091137Z",
          "shell.execute_reply": "2024-01-19T13:34:52.090219Z"
        },
        "papermill": {
          "duration": 0.365423,
          "end_time": "2024-01-19T13:34:52.093272",
          "exception": false,
          "start_time": "2024-01-19T13:34:51.727849",
          "status": "completed"
        },
        "tags": [],
        "id": "Mnate3CbMZQk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Mnate3CbMZQk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6 -  Learning Ratescheduler"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.021442,
          "end_time": "2024-01-19T13:34:52.137585",
          "exception": false,
          "start_time": "2024-01-19T13:34:52.116143",
          "status": "completed"
        },
        "tags": [],
        "id": "qCeZ1maIMZQk"
      },
      "id": "qCeZ1maIMZQk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup optimizer\n",
        "optimizer = get_optimizer(model, lr)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:52.181892Z",
          "iopub.status.busy": "2024-01-19T13:34:52.181605Z",
          "iopub.status.idle": "2024-01-19T13:34:52.19467Z",
          "shell.execute_reply": "2024-01-19T13:34:52.193864Z"
        },
        "papermill": {
          "duration": 0.037328,
          "end_time": "2024-01-19T13:34:52.196468",
          "exception": false,
          "start_time": "2024-01-19T13:34:52.15914",
          "status": "completed"
        },
        "tags": [],
        "id": "YBKMgkNVMZQk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YBKMgkNVMZQk"
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:52.241035Z",
          "iopub.status.busy": "2024-01-19T13:34:52.240787Z",
          "iopub.status.idle": "2024-01-19T13:34:52.245024Z",
          "shell.execute_reply": "2024-01-19T13:34:52.24425Z"
        },
        "papermill": {
          "duration": 0.02857,
          "end_time": "2024-01-19T13:34:52.246796",
          "exception": false,
          "start_time": "2024-01-19T13:34:52.218226",
          "status": "completed"
        },
        "tags": [],
        "id": "NjBVYBJDMZQl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NjBVYBJDMZQl"
    },
    {
      "cell_type": "code",
      "source": [
        "if getattr(accelerator.state, \"fsdp_plugin\", None) is not None:\n",
        "    accelerator.state.fsdp_plugin.auto_wrap_policy = fsdp_auto_wrap_policy(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:52.292064Z",
          "iopub.status.busy": "2024-01-19T13:34:52.291806Z",
          "iopub.status.idle": "2024-01-19T13:34:52.296158Z",
          "shell.execute_reply": "2024-01-19T13:34:52.295416Z"
        },
        "papermill": {
          "duration": 0.029928,
          "end_time": "2024-01-19T13:34:52.298541",
          "exception": false,
          "start_time": "2024-01-19T13:34:52.268613",
          "status": "completed"
        },
        "tags": [],
        "id": "0Q3d4JisMZQl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0Q3d4JisMZQl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7 -  Accelerator setup"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02175,
          "end_time": "2024-01-19T13:34:52.342331",
          "exception": false,
          "start_time": "2024-01-19T13:34:52.320581",
          "status": "completed"
        },
        "tags": [],
        "id": "iJ0xTBfDMZQl"
      },
      "id": "iJ0xTBfDMZQl"
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_dataloader, eval_dataloader, optimizer, lr_scheduler = accelerator.prepare(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    optimizer,\n",
        "    lr_scheduler\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:52.387316Z",
          "iopub.status.busy": "2024-01-19T13:34:52.387023Z",
          "iopub.status.idle": "2024-01-19T13:34:53.381919Z",
          "shell.execute_reply": "2024-01-19T13:34:53.381146Z"
        },
        "papermill": {
          "duration": 1.019797,
          "end_time": "2024-01-19T13:34:53.384176",
          "exception": false,
          "start_time": "2024-01-19T13:34:52.364379",
          "status": "completed"
        },
        "tags": [],
        "id": "B4xz5cTQMZQm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "B4xz5cTQMZQm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DeepSpeed"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023146,
          "end_time": "2024-01-19T13:34:53.429952",
          "exception": false,
          "start_time": "2024-01-19T13:34:53.406806",
          "status": "completed"
        },
        "tags": [],
        "id": "kcT4t36tMZQm"
      },
      "id": "kcT4t36tMZQm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is designed to determine whether the model is currently using the third stage of the DeepSpeed decentralization process (zero_stage). DeepSpeed is a library that optimizes training models on distributed architectures, particularly on GPUs.\n",
        "\n",
        "Detailed explanations:\n",
        "- `accelerator`: It seems to refer to an object that manages hardware acceleration, possibly provided by the Hugging Face Accelerated Inference API.\n",
        "- `accelerator.state`: Accesses the internal state of the accelerator object.\n",
        "- `accelerator.state.deepspeed_plugin`: If DeepSpeed is in use, this accesses the object representing the DeepSpeed plugin within the accelerator state.\n",
        "- `accelerator.state.deepspeed_plugin.zero_stage`: Accesses the current stage of the DeepSpeed decentralization process."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02217,
          "end_time": "2024-01-19T13:34:53.474669",
          "exception": false,
          "start_time": "2024-01-19T13:34:53.452499",
          "status": "completed"
        },
        "tags": [],
        "id": "KLHEPAQpMZQm"
      },
      "id": "KLHEPAQpMZQm"
    },
    {
      "cell_type": "code",
      "source": [
        "is_ds_zero_3 = False\n",
        "if getattr(accelerator.state, \"deepspeed_plugin\", None):\n",
        "    is_ds_zero_3 = accelerator.state.deepspeed_plugin.zero_stage == 3"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:53.521076Z",
          "iopub.status.busy": "2024-01-19T13:34:53.520771Z",
          "iopub.status.idle": "2024-01-19T13:34:53.525192Z",
          "shell.execute_reply": "2024-01-19T13:34:53.524388Z"
        },
        "papermill": {
          "duration": 0.029882,
          "end_time": "2024-01-19T13:34:53.527031",
          "exception": false,
          "start_time": "2024-01-19T13:34:53.497149",
          "status": "completed"
        },
        "tags": [],
        "id": "S4rvOMkCMZQm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "S4rvOMkCMZQm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7 -  Train"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.021301,
          "end_time": "2024-01-19T13:34:53.569953",
          "exception": false,
          "start_time": "2024-01-19T13:34:53.548652",
          "status": "completed"
        },
        "tags": [],
        "id": "pU70u6n-MZQn"
      },
      "id": "pU70u6n-MZQn"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_dataloader, optimizer, lr_scheduler, accelerator):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, disable=not accelerator.is_main_process)):\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.detach().float()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return total_loss / len(train_dataloader)\n",
        "\n",
        "def evaluate_epoch(model, eval_dataloader, tokenizer, accelerator):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation dataset for one epoch.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    eval_preds = []\n",
        "\n",
        "    for step, batch in enumerate(tqdm(eval_dataloader, disable=not accelerator.is_main_process)):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        eval_loss += loss.detach().float()\n",
        "        preds = accelerator.gather_for_metrics(torch.argmax(outputs.logits, -1)).detach().cpu().numpy()\n",
        "        eval_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n",
        "\n",
        "    return eval_loss / len(eval_dataloader), eval_preds\n",
        "\n",
        "def save_model(model, peft_model_name_or_path, accelerator, hub_repo_name):\n",
        "    \"\"\"\n",
        "    Save the model to the specified path.\n",
        "    \"\"\"\n",
        "    accelerator.wait_for_everyone()\n",
        "    model.save_pretrained(peft_model_name_or_path)\n",
        "    tokenizer.save_pretrained(peft_model_name_or_path)\n",
        "    model.push_to_hub(hub_repo_name)\n",
        "    tokenizer.push_to_hub(hub_repo_name)\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "def plot_loss(train_losses, eval_losses):\n",
        "    \"\"\"\n",
        "    Plot training and validation losses.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Move tensors to CPU\n",
        "    train_losses_cpu = [loss.cpu().item() for loss in train_losses]\n",
        "    eval_losses_cpu = [loss.cpu().item() for loss in eval_losses]\n",
        "\n",
        "    epochs = range(1, len(train_losses_cpu) + 1)\n",
        "\n",
        "    plt.plot(epochs, train_losses_cpu, label='Training Loss')\n",
        "    plt.plot(epochs, eval_losses_cpu, label='Validation Loss')\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:53.61444Z",
          "iopub.status.busy": "2024-01-19T13:34:53.614133Z",
          "iopub.status.idle": "2024-01-19T13:34:53.627907Z",
          "shell.execute_reply": "2024-01-19T13:34:53.627065Z"
        },
        "papermill": {
          "duration": 0.038341,
          "end_time": "2024-01-19T13:34:53.629774",
          "exception": false,
          "start_time": "2024-01-19T13:34:53.591433",
          "status": "completed"
        },
        "tags": [],
        "id": "9T7fcswVMZQn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "9T7fcswVMZQn"
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_name_or_path = get_peft_model_name_or_path(model_name_or_path, peft_config)\n",
        "\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "rouge_scores = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    # ---\n",
        "    accelerator_print_sep()\n",
        "    accelerator.print(f\"Train epoch: {epoch=}\")\n",
        "\n",
        "    train_loss = train_epoch(model, train_dataloader, optimizer, lr_scheduler, accelerator)\n",
        "    train_ppl = torch.exp(train_loss)\n",
        "\n",
        "    accelerator_print_sep()\n",
        "    accelerator.print(f\"{epoch=}: {train_ppl=} {train_loss=}\")\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Eval\n",
        "    # ---\n",
        "    accelerator_print_sep()\n",
        "    accelerator.print(f\"Eval epoch: {epoch=}\")\n",
        "\n",
        "    eval_loss, eval_preds = evaluate_epoch(model, eval_dataloader, tokenizer, accelerator)\n",
        "    eval_ppl = torch.exp(eval_loss)\n",
        "\n",
        "    accelerator_print_sep()\n",
        "    accelerator.print(f\"{epoch=}: {eval_ppl=} {eval_loss=}\")\n",
        "\n",
        "    eval_losses.append(eval_loss)\n",
        "\n",
        "    # Save\n",
        "    # ---\n",
        "    accelerator_print_sep()\n",
        "    accelerator.print(f\"Save epoch: {epoch=}\")\n",
        "    save_model(model, peft_model_name_or_path, accelerator, hub_repo_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T13:34:53.674145Z",
          "iopub.status.busy": "2024-01-19T13:34:53.673875Z",
          "iopub.status.idle": "2024-01-19T23:40:02.60656Z",
          "shell.execute_reply": "2024-01-19T23:40:02.605681Z"
        },
        "papermill": {
          "duration": 36308.957607,
          "end_time": "2024-01-19T23:40:02.608993",
          "exception": false,
          "start_time": "2024-01-19T13:34:53.651386",
          "status": "completed"
        },
        "tags": [],
        "id": "ubW0UZrYMZQn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ubW0UZrYMZQn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.624276,
          "end_time": "2024-01-19T23:40:14.272169",
          "exception": false,
          "start_time": "2024-01-19T23:40:08.647893",
          "status": "completed"
        },
        "tags": [],
        "id": "OPkj_sglMZQn"
      },
      "id": "OPkj_sglMZQn"
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(train_losses, eval_losses)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T23:40:26.032122Z",
          "iopub.status.busy": "2024-01-19T23:40:26.031319Z",
          "iopub.status.idle": "2024-01-19T23:40:26.435781Z",
          "shell.execute_reply": "2024-01-19T23:40:26.434758Z"
        },
        "papermill": {
          "duration": 6.341576,
          "end_time": "2024-01-19T23:40:26.437912",
          "exception": false,
          "start_time": "2024-01-19T23:40:20.096336",
          "status": "completed"
        },
        "tags": [],
        "id": "ww4RiMC6MZQn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ww4RiMC6MZQn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cleaning Memory"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.90529,
          "end_time": "2024-01-19T23:40:37.885245",
          "exception": false,
          "start_time": "2024-01-19T23:40:31.979955",
          "status": "completed"
        },
        "tags": [],
        "id": "tgfn05jxMZQo"
      },
      "id": "tgfn05jxMZQo"
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "del train_losses\n",
        "del eval_losses\n",
        "del rouge_scores\n",
        "del lr_scheduler\n",
        "del optimizer\n",
        "del peft_config\n",
        "del train_dataloader\n",
        "del eval_dataloader\n",
        "del tokenizer\n",
        "del data_collator\n",
        "\n",
        "clear_gpu_memory()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-19T23:40:49.65104Z",
          "iopub.status.busy": "2024-01-19T23:40:49.650584Z",
          "iopub.status.idle": "2024-01-19T23:40:50.468738Z",
          "shell.execute_reply": "2024-01-19T23:40:50.467768Z"
        },
        "papermill": {
          "duration": 6.731687,
          "end_time": "2024-01-19T23:40:50.470847",
          "exception": false,
          "start_time": "2024-01-19T23:40:43.73916",
          "status": "completed"
        },
        "tags": [],
        "id": "ZA_vGnXKMZQo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZA_vGnXKMZQo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>3 <span style='color:#78D118'>|</span> Performance Evaluation</b>\n",
        "\n",
        "### Step 1 - Load model and apply Perf"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.584962,
          "end_time": "2024-01-19T23:41:02.0616",
          "exception": false,
          "start_time": "2024-01-19T23:40:56.476638",
          "status": "completed"
        },
        "tags": [],
        "id": "y_6hfmTQMZQo"
      },
      "id": "y_6hfmTQMZQo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Local Load\n",
        "# ----\n",
        "# Load Model\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "#model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
        "\n",
        "# Apply Perf\n",
        "#finetuned_model = PeftModel.from_pretrained(model, peft_model_name_or_path, device_map={\"\":0})\n",
        "\n",
        "# Hub Load\n",
        "# ----\n",
        "tokenizer = AutoTokenizer.from_pretrained(hub_repo_name)\n",
        "finetuned_model = T5ForConditionalGeneration.from_pretrained(hub_repo_name)"
      ],
      "metadata": {
        "papermill": {
          "duration": 62.964347,
          "end_time": "2024-01-19T23:42:10.856452",
          "exception": false,
          "start_time": "2024-01-19T23:41:07.892105",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:22:03.636534Z",
          "iopub.execute_input": "2024-01-20T14:22:03.63684Z",
          "iopub.status.idle": "2024-01-20T14:22:21.950758Z",
          "shell.execute_reply.started": "2024-01-20T14:22:03.636815Z",
          "shell.execute_reply": "2024-01-20T14:22:21.948961Z"
        },
        "trusted": true,
        "id": "U_VTcre2MZQo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "U_VTcre2MZQo"
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model.eval()"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.877527,
          "end_time": "2024-01-19T23:42:22.91991",
          "exception": false,
          "start_time": "2024-01-19T23:42:17.042383",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:22:21.952648Z",
          "iopub.execute_input": "2024-01-20T14:22:21.955179Z",
          "iopub.status.idle": "2024-01-20T14:22:22.009357Z",
          "shell.execute_reply.started": "2024-01-20T14:22:21.955138Z",
          "shell.execute_reply": "2024-01-20T14:22:22.007857Z"
        },
        "trusted": true,
        "id": "HAIUPXw9MZQo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HAIUPXw9MZQo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Pipeline"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.796131,
          "end_time": "2024-01-19T23:42:34.709012",
          "exception": false,
          "start_time": "2024-01-19T23:42:28.912881",
          "status": "completed"
        },
        "tags": [],
        "id": "H4QP5gFMMZQp"
      },
      "id": "H4QP5gFMMZQp"
    },
    {
      "cell_type": "code",
      "source": [
        "text_generation_pipeline = pipeline(\n",
        "    task=pipeline_task,\n",
        "    model=finetuned_model,\n",
        "    tokenizer=tokenizer,\n",
        "    truncation=True,\n",
        "    max_length=pipeline_max_length,\n",
        "    min_length=pipeline_min_length,\n",
        "    temperature=pipeline_temperature,\n",
        "    device=0 # Set device to 0 for GPU, -1 for CPU\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 6.521556,
          "end_time": "2024-01-19T23:42:47.309944",
          "exception": false,
          "start_time": "2024-01-19T23:42:40.788388",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T14:58:40.319963Z",
          "iopub.execute_input": "2024-01-20T14:58:40.320383Z",
          "iopub.status.idle": "2024-01-20T14:58:40.346245Z",
          "shell.execute_reply.started": "2024-01-20T14:58:40.320355Z",
          "shell.execute_reply": "2024-01-20T14:58:40.345468Z"
        },
        "trusted": true,
        "id": "02zuRz2yMZQp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "02zuRz2yMZQp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - Evaluation"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.622358,
          "end_time": "2024-01-19T23:50:05.567622",
          "exception": false,
          "start_time": "2024-01-19T23:49:59.945264",
          "status": "completed"
        },
        "tags": [],
        "id": "U6n_CzyWMZQp"
      },
      "id": "U6n_CzyWMZQp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shot Evaluation"
      ],
      "metadata": {
        "id": "byt-gIKYMZQp"
      },
      "id": "byt-gIKYMZQp"
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "\n",
        "    ## Linked questions\n",
        "    \"How do companies profit from war?\",\n",
        "    \"Why do U.S. companies rebuild towns after wars?\",\n",
        "    \"Is there a World War Hulk movie in production?\",\n",
        "    \"What is the concept of paying off the principal of a home vs. investing in a mutual fund?\",\n",
        "    \"I'm making real money for the first time, what should I do with it?\",\n",
        "    \"How are the first days of each season chosen?\",\n",
        "    \"Why are laws requiring identification for voting scrutinized by the media?\",\n",
        "    \"Why aren't there many new operating systems being created?\",\n",
        "    \"How can schools keep students after the normal school day?\",\n",
        "    \"What are the duties of military personnel stationed in peaceful countries?\",\n",
        "    \"Why did the world's magnetic field reverse 780,000 years ago?\",\n",
        "    \"What is Sherlock Holmes' job?\",\n",
        "    \"Explain the fifthworldproblems subreddit like I'm five.\",\n",
        "    \"Why were Shaq and Kobe seen as rivals despite winning three finals in a row?\",\n",
        "    \"If a filter-feeding whale swallows a turtle, can it digest it normally?\",\n",
        "    \"Why does the pubic region have darker skin than the rest of the body?\",\n",
        "    \"How does the Military-Industrial Complex work?\",\n",
        "    \"Why is there no World War Hulk movie in production?\",\n",
        "    \"What factors should be considered when deciding to pay off a home or invest in a mutual fund?\",\n",
        "    \"What is a Roth IRA, and why is it a good idea to open one?\",\n",
        "\n",
        "    ## Generic questions\n",
        "    \"How do ants decide where to build their colonies?\",\n",
        "    \"What would happen if all the bees disappeared from the Earth?\",\n",
        "    \"Can robots ever have feelings like humans?\",\n",
        "    \"If animals could talk, which species do you think would be the most chatty?\",\n",
        "    \"What would a world without gravity be like?\",\n",
        "    \"If you could time travel, would you go to the past or the future?\",\n",
        "    \"How do plants know when it's time to bloom?\",\n",
        "    \"If you could have any superpower, what would it be and why?\",\n",
        "    \"What if our dreams were actually glimpses of alternate realities?\",\n",
        "    \"How do birds know where to migrate each year?\",\n",
        "    \"If you could create a new color, what would you name it?\",\n",
        "    \"What if everyone on Earth spoke the same language?\",\n",
        "    \"How would life be different if humans had tails?\",\n",
        "    \"If you could be any fictional character for a day, who would you choose?\",\n",
        "    \"What if we discovered a parallel universe right next to ours?\",\n",
        "    \"How do animals in the wild know which plants are safe to eat?\",\n",
        "    \"If you could design a new planet, what features would it have?\",\n",
        "    \"What if we could communicate with dolphins?\",\n",
        "    \"How do clouds decide when to rain?\",\n",
        "    \"If you could swap lives with any person for a week, who would it be and why?\"\n",
        "]"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.774791,
          "end_time": "2024-01-19T23:43:10.679757",
          "exception": false,
          "start_time": "2024-01-19T23:43:04.904966",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T11:42:32.925594Z",
          "iopub.execute_input": "2024-01-20T11:42:32.926474Z",
          "iopub.status.idle": "2024-01-20T11:42:32.933683Z",
          "shell.execute_reply.started": "2024-01-20T11:42:32.92643Z",
          "shell.execute_reply": "2024-01-20T11:42:32.932771Z"
        },
        "trusted": true,
        "id": "UvuWFMR1MZQp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UvuWFMR1MZQp"
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_questions = [prefix + question for question in questions]\n",
        "\n",
        "generated_texts = text_generation_pipeline(transformed_questions, do_sample=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 385.577696,
          "end_time": "2024-01-19T23:49:53.867762",
          "exception": false,
          "start_time": "2024-01-19T23:43:28.290066",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T11:42:33.881164Z",
          "iopub.execute_input": "2024-01-20T11:42:33.882299Z",
          "iopub.status.idle": "2024-01-20T11:49:10.707507Z",
          "shell.execute_reply.started": "2024-01-20T11:42:33.882254Z",
          "shell.execute_reply": "2024-01-20T11:49:10.706616Z"
        },
        "trusted": true,
        "id": "PW8eqZ6vMZQp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PW8eqZ6vMZQp"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [output_text[\"generated_text\"] for output_text in generated_texts]\n",
        "questions = [question.split(\":\")[-1].strip() for question in questions]\n",
        "data = []\n",
        "\n",
        "for question, prediction in zip(questions, predictions):\n",
        "    data.append({\n",
        "        \"Input\": question,\n",
        "        \"Output\": prediction\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "papermill": {
          "duration": 15.824344,
          "end_time": "2024-01-19T23:50:27.305184",
          "exception": false,
          "start_time": "2024-01-19T23:50:11.48084",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-01-20T11:49:10.7092Z",
          "iopub.execute_input": "2024-01-20T11:49:10.709552Z",
          "iopub.status.idle": "2024-01-20T11:49:10.727084Z",
          "shell.execute_reply.started": "2024-01-20T11:49:10.709524Z",
          "shell.execute_reply": "2024-01-20T11:49:10.726112Z"
        },
        "trusted": true,
        "id": "fs3AZWIAMZQq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fs3AZWIAMZQq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rouge Evaluation"
      ],
      "metadata": {
        "id": "AODLKMzXMZQr"
      },
      "id": "AODLKMzXMZQr"
    },
    {
      "cell_type": "code",
      "source": [
        "questions = df.sample(n=50, random_state=seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:00:15.41475Z",
          "iopub.execute_input": "2024-01-20T15:00:15.415663Z",
          "iopub.status.idle": "2024-01-20T15:00:15.423162Z",
          "shell.execute_reply.started": "2024-01-20T15:00:15.41563Z",
          "shell.execute_reply": "2024-01-20T15:00:15.422109Z"
        },
        "trusted": true,
        "id": "Pr53fhDsMZQt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Pr53fhDsMZQt"
    },
    {
      "cell_type": "code",
      "source": [
        "questions.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:00:16.504851Z",
          "iopub.execute_input": "2024-01-20T15:00:16.50533Z",
          "iopub.status.idle": "2024-01-20T15:00:16.516273Z",
          "shell.execute_reply.started": "2024-01-20T15:00:16.5053Z",
          "shell.execute_reply": "2024-01-20T15:00:16.514968Z"
        },
        "trusted": true,
        "id": "UBr4RMY2MZQu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UBr4RMY2MZQu"
    },
    {
      "cell_type": "code",
      "source": [
        "reference_answers = questions['answer']\n",
        "questions = [prefix + question for question in questions['question']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:00:18.550435Z",
          "iopub.execute_input": "2024-01-20T15:00:18.551161Z",
          "iopub.status.idle": "2024-01-20T15:00:18.556062Z",
          "shell.execute_reply.started": "2024-01-20T15:00:18.551128Z",
          "shell.execute_reply": "2024-01-20T15:00:18.554812Z"
        },
        "trusted": true,
        "id": "7rwQa8Q5MZQu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7rwQa8Q5MZQu"
    },
    {
      "cell_type": "code",
      "source": [
        "questions[:1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:00:19.952719Z",
          "iopub.execute_input": "2024-01-20T15:00:19.953559Z",
          "iopub.status.idle": "2024-01-20T15:00:19.962789Z",
          "shell.execute_reply.started": "2024-01-20T15:00:19.953514Z",
          "shell.execute_reply": "2024-01-20T15:00:19.961648Z"
        },
        "trusted": true,
        "id": "ZVtl_VF7MZQv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZVtl_VF7MZQv"
    },
    {
      "cell_type": "code",
      "source": [
        "reference_answers[:1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:00:21.030057Z",
          "iopub.execute_input": "2024-01-20T15:00:21.030442Z",
          "iopub.status.idle": "2024-01-20T15:00:21.037942Z",
          "shell.execute_reply.started": "2024-01-20T15:00:21.030415Z",
          "shell.execute_reply": "2024-01-20T15:00:21.036745Z"
        },
        "trusted": true,
        "id": "BBfd70caMZQv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BBfd70caMZQv"
    },
    {
      "cell_type": "code",
      "source": [
        "generated_texts = text_generation_pipeline(questions, do_sample=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:00:23.157371Z",
          "iopub.execute_input": "2024-01-20T15:00:23.157758Z",
          "iopub.status.idle": "2024-01-20T15:08:04.88552Z",
          "shell.execute_reply.started": "2024-01-20T15:00:23.15773Z",
          "shell.execute_reply": "2024-01-20T15:08:04.884601Z"
        },
        "trusted": true,
        "id": "Zv9ycZIZMZQw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Zv9ycZIZMZQw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The minimum token is set to 20 in the pipeline. The score of Rouge maybe lower for references with little answer."
      ],
      "metadata": {
        "id": "pfxT72b5MZQw"
      },
      "id": "pfxT72b5MZQw"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [output_text[\"generated_text\"] for output_text in generated_texts]\n",
        "data = []\n",
        "\n",
        "for question, reference, prediction in zip(questions, reference_answers, predictions):\n",
        "\n",
        "    rouge_result = rouge_metric.compute(\n",
        "        predictions=[prediction],\n",
        "        references=[reference]\n",
        "    )\n",
        "\n",
        "    data.append({\n",
        "        \"Input\": question.split(\":\")[-1].strip(),\n",
        "        \"Reference\": reference,\n",
        "        \"Output\": prediction,\n",
        "        \"Rouge-1 Score\": rouge_result['rouge1'],\n",
        "        \"Rouge-2 Score\": rouge_result['rouge2'],\n",
        "        \"Rouge-L Score\": rouge_result['rougeL'],\n",
        "        \"Rouge-Lsum Score\": rouge_result['rougeLsum'],\n",
        "    })\n",
        "\n",
        "df_result = pd.DataFrame(data)\n",
        "\n",
        "display(df_result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T15:08:04.887376Z",
          "iopub.execute_input": "2024-01-20T15:08:04.88775Z",
          "iopub.status.idle": "2024-01-20T15:08:17.495996Z",
          "shell.execute_reply.started": "2024-01-20T15:08:04.887708Z",
          "shell.execute_reply": "2024-01-20T15:08:17.494917Z"
        },
        "trusted": true,
        "id": "N8F5lj_LMZQw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "N8F5lj_LMZQw"
    }
  ]
}